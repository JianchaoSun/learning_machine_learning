{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flower.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JianchaoSun/learning_machine_learning/blob/master/flower.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzH6Ixf7WjM_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "121246af-2d10-4748-949e-bd2c63328854"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiHZE6ChYA4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls \"/content/drive/My Drive\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhsfL2dMYS-P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "720d5d1a-6cec-4283-cc70-67f50a58570e"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
        "from tensorflow.python.keras.layers.convolutional import Conv2D, MaxPooling2D \n",
        "tf.keras.__version__"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.4-tf'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvCDJvxScgmx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c5c6052-dc46-4b56-8cea-6509d73c8da9"
      },
      "source": [
        "import os\n",
        "\n",
        "\n",
        "import tarfile\n",
        "tar = tarfile.open('drive/My Drive/flower/flower_photos.tgz', \"r:gz\")\n",
        "tar.extractall('unzipped_folder')\n",
        "tar.close()\n",
        "base_path = 'unzipped_folder/flower_photos/'\n",
        "categories = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
        "\n",
        "fnames = []\n",
        "for category in categories:\n",
        "    flower_folder = os.path.join(base_path, category)\n",
        "    file_names = os.listdir(flower_folder)\n",
        "    full_path = [os.path.join(flower_folder, file_name) for file_name in file_names]\n",
        "    fnames.append(full_path)\n",
        "print('length for each category:', [len(f) for f in fnames])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length for each category: [633, 898, 641, 699, 799]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW9lqwzYmM3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "images = []\n",
        "for names in fnames:\n",
        "    one_category_images = [cv2.imread(name) for name in names if (cv2.imread(name)) is not None]\n",
        "    images.append(one_category_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc9HwWfbmwif",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27728e12-dcc5-4d9b-9d93-f6174dbbcd9e"
      },
      "source": [
        "from skimage.transform import resize\n",
        "img_width, img_height = 256, 256\n",
        "\n",
        "img = images[3][659]\n",
        "print(img.shape)\n",
        "resized_img = resize(img, (img_width, img_height, 3))\n",
        "resized_img2 = cv2.resize(img,(img_width, img_height), interpolation = cv2.INTER_CUBIC)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(213, 320, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEgsS17Hm71P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resized_images = []\n",
        "for i,imgs in enumerate(images):\n",
        "    resized_images.append([cv2.resize(img, (img_width, img_height), interpolation = cv2.INTER_CUBIC) for img in imgs])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeMEIWa5nCzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_images = []\n",
        "val_images = []\n",
        "for imgs in resized_images:\n",
        "    train, test = train_test_split(imgs, train_size=0.8, test_size=0.2)\n",
        "    train_images.append(train)\n",
        "    val_images.append(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHskOgcvnQot",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "54720e1a-d682-471b-ad34-f4f3d2ef5a27"
      },
      "source": [
        "from tensorflow.python.keras.utils import np_utils\n",
        "import numpy as np\n",
        "\n",
        "len_train_images = [len(imgs) for imgs in train_images]\n",
        "print(len_train_images)\n",
        "print('sum of train images:', np.sum(len_train_images))\n",
        "train_categories = np.zeros((np.sum(len_train_images)), dtype='uint8')\n",
        "for i in range(5):\n",
        "    if i is 0:\n",
        "        train_categories[:len_train_images[i]] = i\n",
        "    else:\n",
        "        train_categories[np.sum(len_train_images[:i]):np.sum(len_train_images[:i+1])] = i\n",
        "        \n",
        "len_val_images = [len(imgs) for imgs in val_images]\n",
        "print(len_val_images)\n",
        "print('sum of val_images:', np.sum(len_val_images))\n",
        "val_categories = np.zeros((np.sum(len_val_images)), dtype='uint8')\n",
        "for i in range(5):\n",
        "    if i is 0:\n",
        "        val_categories[:len_val_images[i]] = i\n",
        "    else:\n",
        "        val_categories[np.sum(len_val_images[:i]):np.sum(len_val_images[:i+1])] = i"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[506, 718, 512, 559, 639]\n",
            "sum of train images: 2934\n",
            "[127, 180, 129, 140, 160]\n",
            "sum of val_images: 736\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BiTIP2fnhcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "tmp_train_imgs = []\n",
        "tmp_val_imgs = []\n",
        "for imgs in train_images:\n",
        "    tmp_train_imgs += imgs\n",
        "for imgs in val_images:\n",
        "    tmp_val_imgs += imgs\n",
        "train_images = np.array(tmp_train_imgs)\n",
        "val_images = np.array(tmp_val_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5EH0TUVHMKs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "1009121e-2edf-4159-e91e-4bfe77236159"
      },
      "source": [
        "print('Before converting')\n",
        "print('train data:', train_images.shape)\n",
        "print('train labels:', train_categories.shape)\n",
        "\n",
        "train_data = train_images.astype('float32')\n",
        "val_data = val_images.astype('float32')\n",
        "train_labels = np_utils.to_categorical(train_categories, len(categories))\n",
        "val_labels = np_utils.to_categorical(val_categories, len(categories))\n",
        "print()\n",
        "print('After converting')\n",
        "print('train data:', train_data.shape)\n",
        "print('train labels:', train_labels.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before converting\n",
            "train data: (2934, 256, 256, 3)\n",
            "train labels: (2934,)\n",
            "\n",
            "After converting\n",
            "train data: (2934, 256, 256, 3)\n",
            "train labels: (2934, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eiqy9e6sHTFj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "68f38379-1735-401f-a4f2-2d245cdaa2a6"
      },
      "source": [
        "#build my own cnn\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
        "from tensorflow.python.keras.layers.convolutional import Conv2D, MaxPooling2D \n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding='same', input_shape = (256,256,3), activation='relu', name='conv_1'))\n",
        "model.add(Conv2D(32, (3,3), activation='relu', name='conv_2'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), name='maxpool_1'))\n",
        "model.add(Dropout(0.45))\n",
        "\n",
        "model.add(Conv2D(32, (3,3), padding='same', activation='relu', name='conv_3'))\n",
        "model.add(Conv2D(32, (3,3), activation='relu', name='conv_4'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), name='maxpool_2'))\n",
        "model.add(Dropout(0.45))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu', name='dense_1'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu', name='dense_2'))\n",
        "model.add(Dense(len(categories), name='output'))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_1 (Conv2D)              (None, 256, 256, 32)      896       \n",
            "_________________________________________________________________\n",
            "conv_2 (Conv2D)              (None, 254, 254, 32)      9248      \n",
            "_________________________________________________________________\n",
            "maxpool_1 (MaxPooling2D)     (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_3 (Conv2D)              (None, 127, 127, 32)      9248      \n",
            "_________________________________________________________________\n",
            "conv_4 (Conv2D)              (None, 125, 125, 32)      9248      \n",
            "_________________________________________________________________\n",
            "maxpool_2 (MaxPooling2D)     (None, 62, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 62, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 123008)            0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               62980608  \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 5)                 325       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 63,042,405\n",
            "Trainable params: 63,042,405\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFQ3eiTRHbEX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "7c152ea8-0a82-473b-d09d-60f03415f02d"
      },
      "source": [
        "model.fit(train_data, train_labels, batch_size = 64, epochs = 10, validation_data = (val_data, val_labels))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2934 samples, validate on 736 samples\n",
            "Epoch 1/10\n",
            "2934/2934 [==============================] - 18s 6ms/sample - loss: 143.3718 - acc: 0.2219 - val_loss: 1.5945 - val_acc: 0.2283\n",
            "Epoch 2/10\n",
            "2934/2934 [==============================] - 13s 4ms/sample - loss: 1.5641 - acc: 0.2628 - val_loss: 1.5515 - val_acc: 0.3356\n",
            "Epoch 3/10\n",
            "2934/2934 [==============================] - 13s 4ms/sample - loss: 1.4378 - acc: 0.3715 - val_loss: 1.4048 - val_acc: 0.4389\n",
            "Epoch 4/10\n",
            "2934/2934 [==============================] - 13s 4ms/sample - loss: 1.2925 - acc: 0.4427 - val_loss: 1.3152 - val_acc: 0.4796\n",
            "Epoch 5/10\n",
            "2934/2934 [==============================] - 13s 4ms/sample - loss: 1.1594 - acc: 0.5276 - val_loss: 1.3035 - val_acc: 0.4579\n",
            "Epoch 6/10\n",
            "2934/2934 [==============================] - 13s 4ms/sample - loss: 1.0740 - acc: 0.5842 - val_loss: 1.2403 - val_acc: 0.5054\n",
            "Epoch 7/10\n",
            "2934/2934 [==============================] - 13s 5ms/sample - loss: 0.9428 - acc: 0.6339 - val_loss: 1.2286 - val_acc: 0.5000\n",
            "Epoch 8/10\n",
            "2934/2934 [==============================] - 13s 5ms/sample - loss: 0.8435 - acc: 0.6776 - val_loss: 1.2908 - val_acc: 0.4946\n",
            "Epoch 9/10\n",
            "2934/2934 [==============================] - 13s 5ms/sample - loss: 0.7411 - acc: 0.7297 - val_loss: 1.2629 - val_acc: 0.5054\n",
            "Epoch 10/10\n",
            "2934/2934 [==============================] - 13s 5ms/sample - loss: 0.6747 - acc: 0.7509 - val_loss: 1.3398 - val_acc: 0.4837\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f05401af4a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRbVKJ1klf9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#use vgg19 pre trained model\n",
        "\n",
        "from tensorflow.python.keras.applications import VGG19\n",
        "model = VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
        "    \n",
        "    # Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
        "for layer in model.layers[:1]:\n",
        "  layer.trainable = False\n",
        "  \n",
        "    #Adding custom Layers \n",
        "x = model.output\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "predictions = Dense(len(categories), activation=\"softmax\")(x)\n",
        "\n",
        "# creating the final model \n",
        "vggmodel = tf.keras.models.Model(inputs = model.input, outputs = predictions)\n",
        "vggmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g4ZUPetoBIr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1003
        },
        "outputId": "6060d4cd-5c5a-40df-fe4b-c1080eab5a1b"
      },
      "source": [
        "vggmodel.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              33555456  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 5125      \n",
            "=================================================================\n",
            "Total params: 53,584,965\n",
            "Trainable params: 53,584,965\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Asqo83-Moe8H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "e9ddac7c-25e6-47f5-d7f6-e91bd96f3a09"
      },
      "source": [
        "vgg = vggmodel.fit(train_data, train_labels, batch_size = 64, epochs = 8, validation_data = (val_data, val_labels))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2934 samples, validate on 736 samples\n",
            "Epoch 1/8\n",
            "2934/2934 [==============================] - 64s 22ms/sample - loss: 8.7564 - acc: 0.2512 - val_loss: 1.5784 - val_acc: 0.3084\n",
            "Epoch 2/8\n",
            "2934/2934 [==============================] - 64s 22ms/sample - loss: 1.5509 - acc: 0.3132 - val_loss: 1.5025 - val_acc: 0.3288\n",
            "Epoch 3/8\n",
            "2934/2934 [==============================] - 64s 22ms/sample - loss: 1.4373 - acc: 0.3637 - val_loss: 1.3083 - val_acc: 0.4565\n",
            "Epoch 4/8\n",
            "2934/2934 [==============================] - 64s 22ms/sample - loss: 1.2919 - acc: 0.4414 - val_loss: 1.2222 - val_acc: 0.4823\n",
            "Epoch 5/8\n",
            "2934/2934 [==============================] - 65s 22ms/sample - loss: 1.2690 - acc: 0.4499 - val_loss: 1.1892 - val_acc: 0.5109\n",
            "Epoch 6/8\n",
            "2934/2934 [==============================] - 65s 22ms/sample - loss: 1.2577 - acc: 0.4530 - val_loss: 1.1841 - val_acc: 0.5177\n",
            "Epoch 7/8\n",
            "2934/2934 [==============================] - 65s 22ms/sample - loss: 1.2227 - acc: 0.4819 - val_loss: 1.1998 - val_acc: 0.5068\n",
            "Epoch 8/8\n",
            "2934/2934 [==============================] - 65s 22ms/sample - loss: 1.1713 - acc: 0.5092 - val_loss: 1.1785 - val_acc: 0.4823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YnqgBmyRdSz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "3ba1acff-199c-4d70-f2e8-023754607f79"
      },
      "source": [
        "#Task 4: Apply Data Augmentation to vgg 19\n",
        "from tensorflow.python.keras.applications.vgg19 import preprocess_input\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "image_size = 224\n",
        "\n",
        "datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "                                   horizontal_flip=True,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2)\n",
        "\n",
        "datagen.fit(train_data)\n",
        "\n",
        "\n",
        "vggmodel.fit_generator(datagen.flow(train_data, train_labels, batch_size=32),\n",
        "                    steps_per_epoch=len(train_data) / 32, epochs=10)\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "92/91 [==============================] - 64s 697ms/step - loss: 1.3396 - acc: 0.4294\n",
            "Epoch 2/10\n",
            "92/91 [==============================] - 56s 612ms/step - loss: 1.2524 - acc: 0.4530\n",
            "Epoch 3/10\n",
            "92/91 [==============================] - 57s 620ms/step - loss: 1.2611 - acc: 0.4744\n",
            "Epoch 4/10\n",
            "92/91 [==============================] - 57s 625ms/step - loss: 1.1765 - acc: 0.5027\n",
            "Epoch 5/10\n",
            "92/91 [==============================] - 58s 628ms/step - loss: 1.1683 - acc: 0.5109\n",
            "Epoch 6/10\n",
            "92/91 [==============================] - 58s 630ms/step - loss: 1.1579 - acc: 0.5194\n",
            "Epoch 7/10\n",
            "92/91 [==============================] - 58s 631ms/step - loss: 1.1380 - acc: 0.5382\n",
            "Epoch 8/10\n",
            "92/91 [==============================] - 58s 631ms/step - loss: 1.1452 - acc: 0.5392\n",
            "Epoch 9/10\n",
            "92/91 [==============================] - 58s 632ms/step - loss: 1.1176 - acc: 0.5481\n",
            "Epoch 10/10\n",
            "92/91 [==============================] - 58s 632ms/step - loss: 1.0773 - acc: 0.5596\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f02f07cbfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gum-4esWZ4SJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}